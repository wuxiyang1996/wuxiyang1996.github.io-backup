<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications | Xiyang Wu</title>
    <link>https://wuxiyang1996.github.io/publication/</link>
      <atom:link href="https://wuxiyang1996.github.io/publication/index.xml" rel="self" type="application/rss+xml" />
    <description>Publications</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 02 Nov 2021 02:06:07 -0800</lastBuildDate>
    <image>
      <url>https://wuxiyang1996.github.io/images/icon_hu246a7c5ca50c5215763d04ff4b959e84_299833_512x512_fill_lanczos_center_2.png</url>
      <title>Publications</title>
      <link>https://wuxiyang1996.github.io/publication/</link>
    </image>
    
    <item>
      <title>BARK-COVID: An XGBoost Model to Predict Hospitalization at time of COVID-19 Diagnosis</title>
      <link>https://wuxiyang1996.github.io/publication/bark_2021/</link>
      <pubDate>Tue, 02 Nov 2021 02:06:07 -0800</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/bark_2021/</guid>
      <description>&lt;p&gt;This project intends to develop a prediction model with machine learning methods for COVID-19 diagnosis. The model reads patients&#39; clinical history, bio-medical measurements and physical features and make binary classification that predicts 30-day hospital admission for COVID-19 patients. The baseline methods include ElasticNet, Gaussian Naive Bayes Classifier and Logistic Regression. The prediction is evaluated by several metrics based on the confusion matrix. The final prediction model achieves an accuracy over 80%. My responsibility in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analyze and filter clinical history, bio-medical testing and physical features in raw datasets, impute missing values via iterativeimputer, establish 5 folder training and testing dataset for prediction&lt;/li&gt;
&lt;li&gt;Implement several machine learning models, including ElasticNet, Gaussian Naive Bayes Classifier, Logistic Regression and XGBoost to predict 30-day hospital admission for COVID-19 patients&lt;/li&gt;
&lt;li&gt;Analyze and visualize prediction results generated by each model, compared the prediction with actual 30-day admission records&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Translation Model from PPG to ABP</title>
      <link>https://wuxiyang1996.github.io/publication/signal_2021/</link>
      <pubDate>Tue, 10 Aug 2021 02:06:07 -0800</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/signal_2021/</guid>
      <description>&lt;p&gt;This project intends to develop the translation model that interprets non-invasive blood pressure measurement Photoplethysmography (PPG) into invasive measurement Arterial Blood Pressure (ABP). Several distinct approaches have been made to achieve this goal. The first approach uses generative model for time series translation, while another one extracts indirect measurements for PPG signal and investigate their co-relation with systolic and diastolic blood pressure extracted from ABP signal. Heart Rate Variability (HRV) analysis is also made to achieve an overall image of all kinds of blood pressure measurements. My responsibility in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigate the frontier of heart rate analysis and generative model for time series translation, pre-process Arterial Blood Pressure (ABP) and Photoplethysmography (PPG) signal in MIMIC-II waveform dataset&lt;/li&gt;
&lt;li&gt;Implement several benchmarks for the translation task, including TCN, LSTM and autoencoder, analyzed the mechanism for each benchmark and the temporal correlation within time series&lt;/li&gt;
&lt;li&gt;Extract indirect measurement for blood pressure from PPG signal, like Pulse Arrival Time (PAT) and Slope Transit Time (STT), investigate their co-relation with corresponding systolic and diastolic blood pressure extracted from ABP signal&lt;/li&gt;
&lt;li&gt;Extract Heart Rate Variability (HRV) analysis for synchronized heart rate signal ABP, PPG and ECG through PhysioNet Cardiovascular Signal Toolbox&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Learning Heterogeneous Multi-agent Communication for Joint Perception-Control Tasks</title>
      <link>https://wuxiyang1996.github.io/publication/marl_2020/</link>
      <pubDate>Mon, 23 Nov 2020 13:29:16 -0800</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/marl_2020/</guid>
      <description>&lt;p&gt;Focusing on the coopeartive heterogenous MARL in FireCommander2020 environment, which is highly dynamic and stochastic, this project intends to investigate and propose a multi-agent communication learning framework to improve the cooperative behavior in collaborative Markov games and existing MARL algorithms. This project is still ongoing and expected to be done at the end of November. My responsibilities in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigate the state-of-the-art multi-agent reinforcement learning algorithms, analyze the characteristics for several popular MARL algorithm, formulate the multi-agent joint perception-control task in FireCommander environment as a POMDP problem&lt;/li&gt;
&lt;li&gt;Regulate the FireCommander2020 environment for the multi-agent reinforcement learning, incorporate the agent and fire state update, reward computation module within the framework&lt;/li&gt;
&lt;li&gt;Implement several MARL algorithms IDQN, DIAL, CommNet, QMIX, COMA, etc. on the FireCommander environment to learn the coordination and cooperation in the heterogeneous agent team&lt;/li&gt;
&lt;li&gt;Implementing the novel experience sharing method for the optimal coordination and cooperation on the FireCommander environment and compare its performance with the benchmark algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>FireCommander: An Interactive, Probabilistic Multi-agent Environment for Joint Perception-Action Tasks</title>
      <link>https://wuxiyang1996.github.io/publication/rl_2020/</link>
      <pubDate>Sat, 31 Oct 2020 02:06:07 -0800</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/rl_2020/</guid>
      <description>&lt;p&gt;The FireCommander is an interactive, probabilistic joint perception-action reconnaissance environment in which a composite team of agents (e.g., robots) cooperate to fight dynamic, propagating firespots (e.g., targets). In FireCommander game, a team of agents must be tasked to optimally deal with a wildfire situation in an environment with propagating fire areas and some facilities such as houses, hospitals, power stations, etc. The team of agents can accomplish their mission by first sensing (e.g., estimating fire states), communicating the sensed fire-information among each other and then taking action to put the firespots out based on the sensed information (e.g., dropping water on estimated fire locations). The FireCommander environment can be useful for research topics spanning a wide range of applications from Reinforcement Learning (RL) and Learning from Demonstration (LfD), to Coordination, Psychology, Human-Robot Interaction (HRI) and Teaming. My responsibility in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigate the state-of-art of the reinforcement learning, learning from demonstration and multi-agent control, establish the agent kinematics and control model&lt;/li&gt;
&lt;li&gt;Design the simulation environment for the multi-agent firefighting tasks with PyGame based on the real environment setting, fire propagation model, agent kinematics and control model&lt;/li&gt;
&lt;li&gt;Establish the user-interface with PyQt5 to incorporate the user input or scenario design with the simulation environment, design the data storage and animation reconstruction method&lt;/li&gt;
&lt;li&gt;Implement the reward function based on the hierarchy importance of target, implement various scenarios to deal with real-world circumstances&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Online defects detection method for gearboxcover based on the four-source photometric stereo method</title>
      <link>https://wuxiyang1996.github.io/publication/liu-2020/</link>
      <pubDate>Sat, 05 Sep 2020 16:23:35 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/liu-2020/</guid>
      <description>&lt;h2 id=&#34;the-photometric-stereo-method-is-effective-in-online-inspection-tasks-but-its-performance-could-be-negatively-affected-by-the-spatial-deviation-in-raw-image-which-necessarily-exists-in-the-online-inspection-environment-this-article-presents-an-online-scratch-detection-method-based-on-the-four-source-photometric-stereo-method-considering-the-size-of-the-component-the-system-divides-the-inspection-process-into-several-locations-and-generates-the-standard-template-covering-the-whole-component-beforehand-once-the-component-approaches-one-of-the-presupposed-locations-lights-from-different-directions-turn-on-successively-and-the-inspection-system-acquires-images-under-dim-lateral-lights-after-acquisition-the-system-compensates-the-images-acquired-for-their-spatial-deviation-and-coordinates-them-on-the-standard-template-after-coordination-the-system-extracts-the-inspection-region-in-the-coordinated-images-generates-the-curvature-image-with-the-photometric-stereo-method-and-detects-scratches-in-the-curvature-image-two-experiments-are-designed-to-verify-the-feasibility-of-the-inspection-method-and-evaluate-the-systems-performance-in-the-online-inspection-environment-according-to-the-result-the-systems-performance-meets-the-accuracy-requirements-which-verifies-the-feasibility-of-this-inspection-method&#34;&gt;The photometric stereo method is effective in online inspection tasks, but its performance could be negatively affected by the spatial deviation in raw image, which necessarily exists in the online inspection environment. This article presents an online scratch detection method based on the four-source photometric stereo method. Considering the size of the component, the system divides the inspection process into several locations and generates the standard template covering the whole component beforehand. Once the component approaches one of the presupposed locations, lights from different directions turn on successively and the inspection system acquires images under dim lateral lights. After acquisition, the system compensates the images acquired for their spatial deviation, and coordinates them on the standard template. After coordination, the system extracts the inspection region in the coordinated images, generates the curvature image with the photometric stereo method and detects scratches in the curvature image. Two experiments are designed to verify the feasibility of the inspection method and evaluate the system&amp;rsquo;s performance in the online inspection environment. According to the result, the system&amp;rsquo;s performance meets the accuracy requirements, which verifies the feasibility of this inspection method.&lt;/h2&gt;
</description>
    </item>
    
  </channel>
</rss>
