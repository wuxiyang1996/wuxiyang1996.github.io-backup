<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xiyang Wu* | Xiyang Wu</title>
    <link>https://wuxiyang1996.github.io/author/xiyang-wu/</link>
      <atom:link href="https://wuxiyang1996.github.io/author/xiyang-wu/index.xml" rel="self" type="application/rss+xml" />
    <description>Xiyang Wu*</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 02 Nov 2021 02:06:07 -0800</lastBuildDate>
    <image>
      <url>https://wuxiyang1996.github.io/images/icon_hu246a7c5ca50c5215763d04ff4b959e84_299833_512x512_fill_lanczos_center_2.png</url>
      <title>Xiyang Wu*</title>
      <link>https://wuxiyang1996.github.io/author/xiyang-wu/</link>
    </image>
    
    <item>
      <title>BARK-COVID: An XGBoost Model to Predict Hospitalization at time of COVID-19 Diagnosis</title>
      <link>https://wuxiyang1996.github.io/publication/bark_2021/</link>
      <pubDate>Tue, 02 Nov 2021 02:06:07 -0800</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/bark_2021/</guid>
      <description>&lt;p&gt;This project intends to develop a prediction model with machine learning methods for COVID-19 diagnosis. The model reads patients&#39; clinical history, bio-medical measurements and physical features and make binary classification that predicts 30-day hospital admission for COVID-19 patients. The baseline methods include ElasticNet, Gaussian Naive Bayes Classifier and Logistic Regression. The prediction is evaluated by several metrics based on the confusion matrix. The final prediction model achieves an accuracy over 80%. My responsibility in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analyze and filter clinical history, bio-medical testing and physical features in raw datasets, impute missing values via iterativeimputer, establish 5 folder training and testing dataset for prediction&lt;/li&gt;
&lt;li&gt;Implement several machine learning models, including ElasticNet, Gaussian Naive Bayes Classifier, Logistic Regression and XGBoost to predict 30-day hospital admission for COVID-19 patients&lt;/li&gt;
&lt;li&gt;Analyze and visualize prediction results generated by each model, compared the prediction with actual 30-day admission records&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Translation Model from PPG to ABP</title>
      <link>https://wuxiyang1996.github.io/publication/signal_2021/</link>
      <pubDate>Tue, 10 Aug 2021 02:06:07 -0800</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/signal_2021/</guid>
      <description>&lt;p&gt;This project intends to develop the translation model that interprets non-invasive blood pressure measurement Photoplethysmography (PPG) into invasive measurement Arterial Blood Pressure (ABP). Several distinct approaches have been made to achieve this goal. The first approach uses generative model for time series translation, while another one extracts indirect measurements for PPG signal and investigate their co-relation with systolic and diastolic blood pressure extracted from ABP signal. Heart Rate Variability (HRV) analysis is also made to achieve an overall image of all kinds of blood pressure measurements. My responsibility in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigate the frontier of heart rate analysis and generative model for time series translation, pre-process Arterial Blood Pressure (ABP) and Photoplethysmography (PPG) signal in MIMIC-II waveform dataset&lt;/li&gt;
&lt;li&gt;Implement several benchmarks for the translation task, including TCN, LSTM and autoencoder, analyzed the mechanism for each benchmark and the temporal correlation within time series&lt;/li&gt;
&lt;li&gt;Extract indirect measurement for blood pressure from PPG signal, like Pulse Arrival Time (PAT) and Slope Transit Time (STT), investigate their co-relation with corresponding systolic and diastolic blood pressure extracted from ABP signal&lt;/li&gt;
&lt;li&gt;Extract Heart Rate Variability (HRV) analysis for synchronized heart rate signal ABP, PPG and ECG through PhysioNet Cardiovascular Signal Toolbox&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Learning Heterogeneous Multi-agent Communication for Joint Perception-Control Tasks</title>
      <link>https://wuxiyang1996.github.io/publication/marl_2020/</link>
      <pubDate>Mon, 23 Nov 2020 13:29:16 -0800</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/marl_2020/</guid>
      <description>&lt;p&gt;Focusing on the coopeartive heterogenous MARL in FireCommander2020 environment, which is highly dynamic and stochastic, this project intends to investigate and propose a multi-agent communication learning framework to improve the cooperative behavior in collaborative Markov games and existing MARL algorithms. This project is still ongoing and expected to be done at the end of November. My responsibilities in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigate the state-of-the-art multi-agent reinforcement learning algorithms, analyze the characteristics for several popular MARL algorithm, formulate the multi-agent joint perception-control task in FireCommander environment as a POMDP problem&lt;/li&gt;
&lt;li&gt;Regulate the FireCommander2020 environment for the multi-agent reinforcement learning, incorporate the agent and fire state update, reward computation module within the framework&lt;/li&gt;
&lt;li&gt;Implement several MARL algorithms IDQN, DIAL, CommNet, QMIX, COMA, etc. on the FireCommander environment to learn the coordination and cooperation in the heterogeneous agent team&lt;/li&gt;
&lt;li&gt;Implementing the novel experience sharing method for the optimal coordination and cooperation on the FireCommander environment and compare its performance with the benchmark algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>FireCommander: An Interactive, Probabilistic Multi-agent Environment for Joint Perception-Action Tasks</title>
      <link>https://wuxiyang1996.github.io/publication/rl_2020/</link>
      <pubDate>Sat, 31 Oct 2020 02:06:07 -0800</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/rl_2020/</guid>
      <description>&lt;p&gt;The FireCommander is an interactive, probabilistic joint perception-action reconnaissance environment in which a composite team of agents (e.g., robots) cooperate to fight dynamic, propagating firespots (e.g., targets). In FireCommander game, a team of agents must be tasked to optimally deal with a wildfire situation in an environment with propagating fire areas and some facilities such as houses, hospitals, power stations, etc. The team of agents can accomplish their mission by first sensing (e.g., estimating fire states), communicating the sensed fire-information among each other and then taking action to put the firespots out based on the sensed information (e.g., dropping water on estimated fire locations). The FireCommander environment can be useful for research topics spanning a wide range of applications from Reinforcement Learning (RL) and Learning from Demonstration (LfD), to Coordination, Psychology, Human-Robot Interaction (HRI) and Teaming. My responsibility in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigate the state-of-art of the reinforcement learning, learning from demonstration and multi-agent control, establish the agent kinematics and control model&lt;/li&gt;
&lt;li&gt;Design the simulation environment for the multi-agent firefighting tasks with PyGame based on the real environment setting, fire propagation model, agent kinematics and control model&lt;/li&gt;
&lt;li&gt;Establish the user-interface with PyQt5 to incorporate the user input or scenario design with the simulation environment, design the data storage and animation reconstruction method&lt;/li&gt;
&lt;li&gt;Implement the reward function based on the hierarchy importance of target, implement various scenarios to deal with real-world circumstances&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Online defects detection method for gearboxcover based on the four-source photometric stereo method</title>
      <link>https://wuxiyang1996.github.io/publication/liu-2020/</link>
      <pubDate>Sat, 05 Sep 2020 16:23:35 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/liu-2020/</guid>
      <description>&lt;h2 id=&#34;the-photometric-stereo-method-is-effective-in-online-inspection-tasks-but-its-performance-could-be-negatively-affected-by-the-spatial-deviation-in-raw-image-which-necessarily-exists-in-the-online-inspection-environment-this-article-presents-an-online-scratch-detection-method-based-on-the-four-source-photometric-stereo-method-considering-the-size-of-the-component-the-system-divides-the-inspection-process-into-several-locations-and-generates-the-standard-template-covering-the-whole-component-beforehand-once-the-component-approaches-one-of-the-presupposed-locations-lights-from-different-directions-turn-on-successively-and-the-inspection-system-acquires-images-under-dim-lateral-lights-after-acquisition-the-system-compensates-the-images-acquired-for-their-spatial-deviation-and-coordinates-them-on-the-standard-template-after-coordination-the-system-extracts-the-inspection-region-in-the-coordinated-images-generates-the-curvature-image-with-the-photometric-stereo-method-and-detects-scratches-in-the-curvature-image-two-experiments-are-designed-to-verify-the-feasibility-of-the-inspection-method-and-evaluate-the-systems-performance-in-the-online-inspection-environment-according-to-the-result-the-systems-performance-meets-the-accuracy-requirements-which-verifies-the-feasibility-of-this-inspection-method&#34;&gt;The photometric stereo method is effective in online inspection tasks, but its performance could be negatively affected by the spatial deviation in raw image, which necessarily exists in the online inspection environment. This article presents an online scratch detection method based on the four-source photometric stereo method. Considering the size of the component, the system divides the inspection process into several locations and generates the standard template covering the whole component beforehand. Once the component approaches one of the presupposed locations, lights from different directions turn on successively and the inspection system acquires images under dim lateral lights. After acquisition, the system compensates the images acquired for their spatial deviation, and coordinates them on the standard template. After coordination, the system extracts the inspection region in the coordinated images, generates the curvature image with the photometric stereo method and detects scratches in the curvature image. Two experiments are designed to verify the feasibility of the inspection method and evaluate the system&amp;rsquo;s performance in the online inspection environment. According to the result, the system&amp;rsquo;s performance meets the accuracy requirements, which verifies the feasibility of this inspection method.&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>FireCommander 2020 – Multi-agent Wildfire Pruning System based on Learning from Demonstration</title>
      <link>https://wuxiyang1996.github.io/project/rl_2020/</link>
      <pubDate>Thu, 30 Jul 2020 18:27:45 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/project/rl_2020/</guid>
      <description>&lt;p&gt;FireCommander 2020 is a project that intends to derive an optimal heterogenous multi-agent team control method via inverse reinforcement learning. The multi-agent control is based on the massive user data collected through online interactive platform and optimized with inverse reinforcement learning method. My responsibility in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigate the state-of-art of the reinforcement learning, learning from demonstration and multi-agent control, analyze the multi-agent control problem with the mathematical model like AEKF&lt;/li&gt;
&lt;li&gt;Design the simulation environment for the multi-agent firefighting tasks with PyGame based on the real environment setting, fire propagation model, agent kinematics and control mode, established the user-interface with PyQt5, design the data storage and animation reconstruction method&lt;/li&gt;
&lt;li&gt;Implement the reward function based on the relative importance of target, designed various scenarios to deal with real-world circumstances, set up the online platform for massive user data collection, processed the data acquired&lt;/li&gt;
&lt;li&gt;Design and optimize the multi-agent firefighting control method based on the multi-agent learning from demonstration algorithm and user data collected&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Fake News Detection Neural Network and LSTM</title>
      <link>https://wuxiyang1996.github.io/project/fake_news/</link>
      <pubDate>Thu, 30 Apr 2020 20:15:23 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/project/fake_news/</guid>
      <description>&lt;p&gt;Fake News Detection intends to implement the text classification method on the Kaggle fake new dataset and compare the performance of different methods. In this project, the text classification methods involve the supervised methods like SVM, Naive Bayes Classifier and XGBoost, unsupervised methods like KMeans and GMM, and deep learning methods like Neural Network and LSTM. My responsibility in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigate the multiple text classification methods for the Kaggle Fake News dataset, pre-process the dataset with Doc2Vec method&lt;/li&gt;
&lt;li&gt;Design the basic news classifier with unsupervised methods like K-Means and supervised methods like SVM, implement the deep learning based method like the Neural Network, CNN and LSTM on the same dataset, optimize the classification model and visualize the classification result&lt;/li&gt;
&lt;li&gt;Summarize the experiment result by analyzing and comparing the classification accuracy for the traditional and deep learning methods, write the final report collaboratively&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Content-Weighted Autoencoder for Image Compression</title>
      <link>https://wuxiyang1996.github.io/project/feature_map/</link>
      <pubDate>Sun, 15 Dec 2019 20:37:54 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/project/feature_map/</guid>
      <description>&lt;p&gt;This project presents a novel neural networkstructure for image compression tasks. The network structure utilizes the ResNet autoencoder for the encoder and decoder part, and incorporates the importance map to enhance the details in the image. The result shows that the compression performance of the convolutional autoencoder with the importance map is superior to the traditional 3-layer convolutional autoencoder and the ResNet autoencoder without the importance map under multiple image compression quality metrics. My responsibility in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigate the frontiers of lossy image compression and super-resolution with deep learning methods&lt;/li&gt;
&lt;li&gt;Design the content-weighted autoencoder and the content-weighted importance map and the quantization layer that enhances the important features within the images by deeply compressing the background,&lt;/li&gt;
&lt;li&gt;Compare the performance of the content-weighted autoencoder with the four-layer CNN and ResNet autoencoder without quantization layer using the same encoding size with multiple experiments&lt;/li&gt;
&lt;li&gt;Verify its superior performance in maintaining the high reconstruction quality with low bpp rate&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>BuzzCup - Multi-agent Motion Simulator based on PID, OpenGL and MPI</title>
      <link>https://wuxiyang1996.github.io/project/buzzcup/</link>
      <pubDate>Tue, 03 Dec 2019 20:38:10 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/project/buzzcup/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./BuzzCup.gif&#34; title=&#34;BuzzCup&#34; width=&#34;600&#34; height=&#34;300&#34; /&gt;
Buzzcup intends to simulate the PID control on the circluar motion of multiple agents. The environment is based on the OpenGL and each agent is controlled by a independent thread that communicates via MPI. My responsibily in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigate the multi-thread programming tool for C++, designed the multi-agent control system with MPI to ensure all the agents are controlled by an independent thread&lt;/li&gt;
&lt;li&gt;Implement the PID control method based on the agent’s distance to the sphere center to stabilize the agent’s trajectory during its transferring process and rotating on the sphere&lt;/li&gt;
&lt;li&gt;Visualize the simulation environment with 3-D computer graphics package OpenGL, presented the playground, intended sphere for surrounding and agents with their trajectory during the simulation&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>The OpenGL based Chess</title>
      <link>https://wuxiyang1996.github.io/project/chess/</link>
      <pubDate>Mon, 25 Nov 2019 20:38:15 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/project/chess/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;This project intends to design the 3D chess with OpenGL.The enviroment setting could be changed by the user, like lifting up or down the view point, rotating the chessboard, moving the pieces and switching the model between detailed and simplified ones.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Online Component Scratch Inspection System Based on the Photometric Stereo Method</title>
      <link>https://wuxiyang1996.github.io/project/photometric/</link>
      <pubDate>Thu, 15 Aug 2019 20:38:33 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/project/photometric/</guid>
      <description>&lt;p&gt;This project intends to realize the online scratch inspection tasks on the surface of the complex components. The deviation introduced by conveyer is compensated with shape template matching. The surface variation is reconstructed through photometric stereo method, which helps to extract the defect via local grayscale comparsion. My responsibily covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Survey frontiers of the automatic inspection system for complex components, investigate various scratch detection methods, design the online inspection system with the photometric stereo method&lt;/li&gt;
&lt;li&gt;Coordinate the images in the online inspection environment by shape matching to compensate for the spatial deviation between proximate images, generated and implemented the region template to extract the inspection region at each inspection location&lt;/li&gt;
&lt;li&gt;Generate the curvature image with the photometric stereo method that presents the surface contour in grayscale, detect scratches on the component’s surface with image morphology method&lt;/li&gt;
&lt;li&gt;Summarize and present the investigation result in the undergraduate thesis and the paper Online defects detection method for gearboxcover based on the four-source photometric stereo method&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Design and Simulation of a 5-DOF Writing Manipulator</title>
      <link>https://wuxiyang1996.github.io/project/manipulator/</link>
      <pubDate>Sun, 10 Dec 2017 20:38:51 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/project/manipulator/</guid>
      <description>&lt;p&gt;This project intends to implement the character writing task on an unknown 5-DOF manipulator. The purpose incorporates the analysis of the kinematic and dynamic feature of the manipulator, the mechanical model design and FEA, trajectory planning and basic manipulator control. My responsibily in this project covers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Establish the connecting rod model of the manipulator according to standard D-H Representation, derive its kinematics expression&lt;/li&gt;
&lt;li&gt;Research on trajectory planning methods in joint and Cartesian space, design the trajectory of the actuator, gain the variation of each joint’s outcome during their entire working process with MATLAB Robotic Toolbox, and complete the static analysis of the manipulator&lt;/li&gt;
&lt;li&gt;Build up the 3-D model of the manipulator in SOLIDWORKS, obtain the strain distribution throughout the manipulator under different external forces through finite element analysis, and manage the manipulator’s dynamic analysis with ADAMS&lt;/li&gt;
&lt;li&gt;Established the steering gear mathematical model, design the control and communication system between manipulator and laptop by using LabVIEW and Arduino&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
  </channel>
</rss>
