<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications | Xiyang Wu</title>
    <link>https://wuxiyang1996.github.io/publication/</link>
      <atom:link href="https://wuxiyang1996.github.io/publication/index.xml" rel="self" type="application/rss+xml" />
    <description>Publications</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 30 Sep 2023 16:23:35 -0700</lastBuildDate>
    <image>
      <url>https://wuxiyang1996.github.io/images/icon_hu246a7c5ca50c5215763d04ff4b959e84_299833_512x512_fill_lanczos_center_2.png</url>
      <title>Publications</title>
      <link>https://wuxiyang1996.github.io/publication/</link>
    </image>
    
    <item>
      <title>LANCAR: Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments</title>
      <link>https://wuxiyang1996.github.io/publication/lancar-2023/</link>
      <pubDate>Sat, 30 Sep 2023 16:23:35 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/lancar-2023/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;Robotic locomotion is a challenging task, especially in unstructured terrains. In practice, the optimal locomotion policy can be context-dependent by using the contextual information of encountered terrains in decision-making. Humans can interpret the environmental context for robots, but the ambiguity of human language makes it challenging to use in robot locomotion directly. In this paper, we propose a novel approach that introduces a context translator that works with reinforcement learning (RL) agents for context-aware locomotion. Our formulation allows a robot to interpret the contextual information from environments generated by human observers or Vision-Language Models (VLM) with Large Language Models (LLM) and use this information to generate contextual embeddings. We incorporate the contextual embeddings with the robot&amp;rsquo;s internal environmental observations as the input to the RL agent&amp;rsquo;s decision neural network. We evaluate with contextual information in varying ambiguity levels and compare its performance using several alternative approaches. Our experimental results demonstrate that our approach exhibits good generalizability and adaptability across diverse terrains, by achieving at least 10% of performance improvement in episodic reward over baselines.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@misc{shek2023lancar,
      title={LANCAR: Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments}, 
      author={Chak Lam Shek and Xiyang Wu and Dinesh Manocha and Pratap Tokekar and Amrit Singh Bedi},
      year={2023},
      eprint={2310.00481},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>A novel image registration-based dynamic photometric stereo method for online defect detection in aluminum alloy castings</title>
      <link>https://wuxiyang1996.github.io/publication/liu-2020/</link>
      <pubDate>Fri, 01 Sep 2023 18:04:35 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/liu-2020/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;The adoption of three-dimensional (3D) measurement technology for parts surface defect detection can improve inspection reliability. For online inspection purposes, 3D measurement technologies must possess the characteristics of high speed and high efficiency. The photometric stereo method is a potential 3D measurement method with high speed and low cost. However, the traditional photometric stereo method is unsuitable for dynamic scenes due to its initial design for static scenes. In this paper, we propose a novel dynamic photometric stereo method based on an image registration method. To achieve fast speed and high efficiency, we reduce the computational cost by automatically generating regions of interest (ROI). Additionally, we innovatively map the depth information (the surface normal vectors) to a mean curvature map of the surface and use it to detect defects, which combines the robustness of 3D methods and the fast speed of 2D methods. We designed experiments and the results showed that our method can detect defects on the surfaces of aluminum alloy castings accurately and robustly in an online manner. This paper also aims to reveal the importance of utilizing multidimensional information in high-speed online inspections.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@article{liu2023novel,
  title={A novel image registration-based dynamic photometric stereo method for online defect detection in aluminum alloy castings},
  author={Liu, Haoyue and Wu, Xiyang and Yan, Ning and Yuan, Shuaipeng and Zhang, Xiaodong},
  journal={Digital Signal Processing},
  volume={141},
  pages={104165},
  year={2023},
  publisher={Elsevier}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>iPLAN: Intent-Aware Planning in Heterogeneous Traffic via Distributed Multi-Agent Reinforcement Learning</title>
      <link>https://wuxiyang1996.github.io/publication/iplan-2023/</link>
      <pubDate>Fri, 09 Jun 2023 16:23:35 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/iplan-2023/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;Navigating safely and efficiently in dense and heterogeneous traffic scenarios is challenging for autonomous vehicles (AVs) due to their inability to infer the behaviors or intentions of nearby drivers. In this work, we introduce a distributed multi-agent reinforcement learning (MARL) algorithm for joint trajectory and intent prediction for autonomous vehicles in dense and heterogeneous environments. Our approach for intent-aware planning, iPLAN, allows agents to infer nearby drivers&amp;rsquo; intents solely from their local observations. We model an explicit representation of agents&amp;rsquo; private incentives: Behavioral Incentive for high-level decision-making strategy that sets planning sub-goals and Instant Incentive for low-level motion planning to execute sub-goals. Our approach enables agents to infer their opponents&amp;rsquo; behavior incentives and integrate this inferred information into their decision-making and motion-planning processes. We perform experiments on two simulation environments, Non-Cooperative Navigation and Heterogeneous Highway. In Heterogeneous Highway, results show that, compared with centralized training decentralized execution (CTDE) MARL baselines such as QMIX and MAPPO, our method yields a 4.3% and 38.4% higher episodic reward in mild and chaotic traffic, with 48.1% higher success rate and 80.6% longer survival time in chaotic traffic. We also compare with a decentralized training decentralized execution (DTDE) baseline IPPO and demonstrate a higher episodic reward of 12.7% and 6.3% in mild traffic and chaotic traffic, 25.3% higher success rate, and 13.7% longer survival time.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{wu2023intent, 
  title={Intent-Aware Planning in Heterogeneous Traffic via Distributed Multi-Agent Reinforcement Learning}, 
  author={Wu, Xiyang and Chandra, Rohan and Guan, Tianrui and Bedi, Amrit and Manocha, Dinesh}, 
  booktitle={7th Annual Conference on Robot Learning}, 
  year={2023}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Firecommander: An interactive, probabilistic multi-agent environment for joint perception-action tasks</title>
      <link>https://wuxiyang1996.github.io/publication/firecommander-2020/</link>
      <pubDate>Sat, 31 Oct 2020 16:23:35 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/firecommander-2020/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;The purpose of this tutorial is to help individuals use the \underline{FireCommander} game environment for research applications. The FireCommander is an interactive, probabilistic joint perception-action reconnaissance environment in which a composite team of agents (e.g., robots) cooperate to fight dynamic, propagating firespots (e.g., targets). In FireCommander game, a team of agents must be tasked to optimally deal with a wildfire situation in an environment with propagating fire areas and some facilities such as houses, hospitals, power stations, etc. The team of agents can accomplish their mission by first sensing (e.g., estimating fire states), communicating the sensed fire-information among each other and then taking action to put the firespots out based on the sensed information (e.g., dropping water on estimated fire locations). The FireCommander environment can be useful for research topics spanning a wide range of applications from Reinforcement Learning (RL) and Learning from Demonstration (LfD), to Coordination, Psychology, Human-Robot Interaction (HRI) and Teaming. There are four important facets of the FireCommander environment that overall, create a non-trivial game: (1) Complex Objectives: Multi-objective Stochastic Environment, (2)Probabilistic Environment: Agents&amp;rsquo; actions result in probabilistic performance, (3) Hidden Targets: Partially Observable Environment and, (4) Uni-task Robots: Perception-only and Action-only agents. The FireCommander environment is first-of-its-kind in terms of including Perception-only and Action-only agents for coordination. It is a general multi-purpose game that can be useful in a variety of combinatorial optimization problems and stochastic games, such as applications of Reinforcement Learning (RL), Learning from Demonstration (LfD) and Inverse RL (iRL).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@misc{seraj2021firecommander,
      title={FireCommander: An Interactive, Probabilistic Multi-agent Environment for Heterogeneous Robot Teams}, 
      author={Esmaeil Seraj and Xiyang Wu and Matthew Gombolay},
      year={2021},
      eprint={2011.00165},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
