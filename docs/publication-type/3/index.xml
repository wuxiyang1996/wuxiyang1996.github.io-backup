<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>3 | Xiyang Wu</title>
    <link>https://wuxiyang1996.github.io/publication-type/3/</link>
      <atom:link href="https://wuxiyang1996.github.io/publication-type/3/index.xml" rel="self" type="application/rss+xml" />
    <description>3</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 30 Sep 2023 16:23:35 -0700</lastBuildDate>
    <image>
      <url>https://wuxiyang1996.github.io/images/icon_hu246a7c5ca50c5215763d04ff4b959e84_299833_512x512_fill_lanczos_center_2.png</url>
      <title>3</title>
      <link>https://wuxiyang1996.github.io/publication-type/3/</link>
    </image>
    
    <item>
      <title>LANCAR: Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments</title>
      <link>https://wuxiyang1996.github.io/publication/lancar-2023/</link>
      <pubDate>Sat, 30 Sep 2023 16:23:35 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/lancar-2023/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;Robotic locomotion is a challenging task, especially in unstructured terrains. In practice, the optimal locomotion policy can be context-dependent by using the contextual information of encountered terrains in decision-making. Humans can interpret the environmental context for robots, but the ambiguity of human language makes it challenging to use in robot locomotion directly. In this paper, we propose a novel approach that introduces a context translator that works with reinforcement learning (RL) agents for context-aware locomotion. Our formulation allows a robot to interpret the contextual information from environments generated by human observers or Vision-Language Models (VLM) with Large Language Models (LLM) and use this information to generate contextual embeddings. We incorporate the contextual embeddings with the robot&amp;rsquo;s internal environmental observations as the input to the RL agent&amp;rsquo;s decision neural network. We evaluate with contextual information in varying ambiguity levels and compare its performance using several alternative approaches. Our experimental results demonstrate that our approach exhibits good generalizability and adaptability across diverse terrains, by achieving at least 10% of performance improvement in episodic reward over baselines.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@misc{shek2023lancar,
      title={LANCAR: Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments}, 
      author={Chak Lam Shek and Xiyang Wu and Dinesh Manocha and Pratap Tokekar and Amrit Singh Bedi},
      year={2023},
      eprint={2310.00481},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Firecommander: An interactive, probabilistic multi-agent environment for joint perception-action tasks</title>
      <link>https://wuxiyang1996.github.io/publication/firecommander-2020/</link>
      <pubDate>Sat, 31 Oct 2020 16:23:35 -0700</pubDate>
      <guid>https://wuxiyang1996.github.io/publication/firecommander-2020/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;The purpose of this tutorial is to help individuals use the \underline{FireCommander} game environment for research applications. The FireCommander is an interactive, probabilistic joint perception-action reconnaissance environment in which a composite team of agents (e.g., robots) cooperate to fight dynamic, propagating firespots (e.g., targets). In FireCommander game, a team of agents must be tasked to optimally deal with a wildfire situation in an environment with propagating fire areas and some facilities such as houses, hospitals, power stations, etc. The team of agents can accomplish their mission by first sensing (e.g., estimating fire states), communicating the sensed fire-information among each other and then taking action to put the firespots out based on the sensed information (e.g., dropping water on estimated fire locations). The FireCommander environment can be useful for research topics spanning a wide range of applications from Reinforcement Learning (RL) and Learning from Demonstration (LfD), to Coordination, Psychology, Human-Robot Interaction (HRI) and Teaming. There are four important facets of the FireCommander environment that overall, create a non-trivial game: (1) Complex Objectives: Multi-objective Stochastic Environment, (2)Probabilistic Environment: Agents&amp;rsquo; actions result in probabilistic performance, (3) Hidden Targets: Partially Observable Environment and, (4) Uni-task Robots: Perception-only and Action-only agents. The FireCommander environment is first-of-its-kind in terms of including Perception-only and Action-only agents for coordination. It is a general multi-purpose game that can be useful in a variety of combinatorial optimization problems and stochastic games, such as applications of Reinforcement Learning (RL), Learning from Demonstration (LfD) and Inverse RL (iRL).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@misc{seraj2021firecommander,
      title={FireCommander: An Interactive, Probabilistic Multi-agent Environment for Heterogeneous Robot Teams}, 
      author={Esmaeil Seraj and Xiyang Wu and Matthew Gombolay},
      year={2021},
      eprint={2011.00165},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
